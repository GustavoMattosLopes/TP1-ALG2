{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e0e84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/luisalopescarvalhaes/.local/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: unidecode in /home/luisalopescarvalhaes/.local/lib/python3.13/site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/lib64/python3.13/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/lib/python3.13/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/luisalopescarvalhaes/.local/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/luisalopescarvalhaes/.local/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprimeiro cross matching\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! pip install pandas unidecode\n",
    "# TODO: organizer isso dps, e descrever o preocessamento\n",
    "\"\"\"\n",
    "primeiro cross matching\n",
    "depois mathcing fuzzy/relaxado - matchings.txt\n",
    "depois ajustes manuais\n",
    "geramos dados_com_cdb\n",
    "\"\"\"\n",
    "\n",
    "# NAO RODAR CELULAS DESSE NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross.py\n",
    "import pandas as pd\n",
    "\n",
    "# Leitura dos dados\n",
    "data = pd.read_csv(\"dados_filtrados.csv\")\n",
    "cdb = pd.read_csv(\"bares_cdb2025.csv\")\n",
    "\n",
    "# Normalização dos textos\n",
    "data[\"NOME_FANTASIA\"] = data[\"NOME_FANTASIA\"].str.upper().str.strip()\n",
    "data[\"ENDERECO_COMPLETO\"] = data[\"ENDERECO_COMPLETO\"].str.upper().str.strip()\n",
    "\n",
    "cdb[\"Nome\"] = cdb[\"Nome\"].str.upper().str.strip()\n",
    "cdb[\"Endereço\"] = cdb[\"Endereço\"].str.upper().str.strip()\n",
    "\n",
    "# Conjuntos de referência\n",
    "nomes_ref = set(data[\"NOME_FANTASIA\"])\n",
    "enderecos_ref = set(data[\"ENDERECO_COMPLETO\"])\n",
    "\n",
    "# Listas para armazenar resultados\n",
    "nao_encontrados = []\n",
    "encontrados = []\n",
    "\n",
    "# Verificação de existência\n",
    "for _, row in cdb.iterrows():\n",
    "    nome = row[\"Nome\"]\n",
    "    endereco = row[\"Endereço\"]\n",
    "\n",
    "    if endereco in enderecos_ref:\n",
    "        encontrados.append({\n",
    "            \"Nome\": nome,\n",
    "            \"Endereço\": endereco\n",
    "        })\n",
    "    else:\n",
    "        nao_encontrados.append({\n",
    "            \"Nome\": nome,\n",
    "            \"Endereço\": endereco\n",
    "        })\n",
    "\n",
    "# Impressão dos não encontrados\n",
    "for item in nao_encontrados:\n",
    "    print(f'Não encontrado: {item[\"Nome\"]} - {item[\"Endereço\"]}')\n",
    "\n",
    "# Salvando os resultados\n",
    "pd.DataFrame(nao_encontrados).to_csv(\"nao_encontrados.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "pd.DataFrame(encontrados).to_csv(\"encontrados.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f52bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "def normalizar(texto):\n",
    "    if pd.isna(texto):\n",
    "        return \"\"\n",
    "    return unidecode(texto.strip().upper())\n",
    "\n",
    "def extrair_rua(endereco):\n",
    "    return normalizar(endereco.split(\",\")[0])\n",
    "\n",
    "def nome_bate(nome_csv1, nome_csv2, nome_fantasia):\n",
    "    palavras = [normalizar(p) for p in nome_csv1.split()]\n",
    "    nome_csv2 = normalizar(nome_csv2)\n",
    "    nome_fantasia = normalizar(nome_fantasia)\n",
    "    return any(p in nome_csv2 or p in nome_fantasia for p in palavras)\n",
    "\n",
    "def endereco_bate(end1, end2):\n",
    "    return extrair_rua(end1) in normalizar(end2)\n",
    "\n",
    "csv1 = pd.read_csv(\"nao_encontrados.csv\") \n",
    "csv2 = pd.read_csv(\"dados_filtrados.csv\")  \n",
    "\n",
    "with open(\"matchings.txt\", \"w\", encoding=\"utf-8\") as output:\n",
    "    for _, row1 in csv1.iterrows():\n",
    "        nome1 = str(row1[\"Nome\"])\n",
    "        endereco1 = str(row1[\"Endereço\"])\n",
    "\n",
    "        output.write(f'{nome1},\"{endereco1}\"\\n')\n",
    "        output.write(\"matchings (pode haver mais de um):\\n\")\n",
    "\n",
    "        achou = False\n",
    "        for _, row2 in csv2.iterrows():\n",
    "            nome_real = str(row2.get(\"NOME\", \"\"))\n",
    "            nome_fantasia = str(row2.get(\"NOME_FANTASIA\", \"\"))\n",
    "            endereco2 = str(row2.get(\"ENDERECO_COMPLETO\", \"\"))\n",
    "\n",
    "            if nome_bate(nome1, nome_real, nome_fantasia) and endereco_bate(endereco1, endereco2):\n",
    "                output.write(f'\"{endereco2}\"{nome_fantasia, nome_real}\\n')\n",
    "                achou = True\n",
    "\n",
    "        if not achou:\n",
    "            output.write(\"Nenhum matching encontrado.\\n\")\n",
    "        output.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39bb8b",
   "metadata": {},
   "source": [
    "> Aqui fiz um ultimo matching mais flexivel para checar alguns bares - matching.txt\n",
    "\n",
    "CANTINHO DA BAIANA,\"AVENIDA ITAITE, 422, SÃO GERALDO, BELO HORIZONTE, MG, BRASIL\"\n",
    "matchings:\n",
    "\"AVENIDA ITAITE, 422, SAO GERALDO, BELO HORIZONTE, MG, BRASIL\"('Estabelecimento sem nome', 'CANTINHO DA BAIANA COMERCIAL LTDA')\n",
    "\n",
    "BAR DA LU,\"RUA GERALDA MARINHO, 41, SÃO JOÃO BATISTA, BELO HORIZONTE, MG, BRASIL\"\n",
    "matchings:\n",
    "\"RUA GERALDA MARINHO, 41, SAO JOAO BATISTA, BELO HORIZONTE, MG, BRASIL\"('BAR E RESTAURANTE DA LU', '38.029.984 LUZMARINA PEREIRA DAS NEVES')\n",
    "\n",
    "TROPEIRO DO LISBOA,\"AVENIDA LEONTINO FRANCISCO ALVES, 506, SERRA VERDE, BELO HORIZONTE, MG, BRASIL\"\n",
    "matchings:\n",
    "\"AVENIDA LEONTINO FRANCISCO ALVES, 810, SERRA VERDE, BELO HORIZONTE, MG, BRASIL\"('REI DO TROPEIRO', 'REI DO TROPEIRO LTDA')\n",
    "-> checado esse rei do tropeiro tem o mesmo cnpj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e89c8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar os dados\n",
    "data = pd.read_csv(\"dados_filtrados.csv\")\n",
    "cdb = pd.read_csv(\"bares_cdb2025.csv\")\n",
    "\n",
    "# Normalizar campos\n",
    "data[\"NOME_FANTASIA\"] = data[\"NOME_FANTASIA\"].str.upper().str.strip()\n",
    "data[\"ENDERECO_COMPLETO\"] = data[\"ENDERECO_COMPLETO\"].str.upper().str.strip()\n",
    "\n",
    "cdb[\"Nome\"] = cdb[\"Nome\"].str.upper().str.strip()\n",
    "cdb[\"Endereço\"] = cdb[\"Endereço\"].str.upper().str.strip()\n",
    "\n",
    "# Criar sets para comparação\n",
    "enderecos_ref = set(data[\"ENDERECO_COMPLETO\"])\n",
    "\n",
    "# Identificar bares encontrados\n",
    "encontrados = []\n",
    "for _, row in cdb.iterrows():\n",
    "    nome = row[\"Nome\"]\n",
    "    endereco = row[\"Endereço\"]\n",
    "    if endereco in enderecos_ref:\n",
    "        encontrados.append({\"Nome\": nome, \"Endereço\": endereco})\n",
    "\n",
    "# Criar DataFrame dos encontrados com ID\n",
    "df_encontrados = pd.DataFrame(encontrados).drop_duplicates(subset=[\"Endereço\"]).reset_index(drop=True)\n",
    "df_encontrados[\"CDB_ID\"] = df_encontrados.index + 1\n",
    "df_encontrados.to_csv(\"encontrados.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# Criar dicionários para mapeamento\n",
    "map_endereco_to_id = dict(zip(df_encontrados[\"Endereço\"], df_encontrados[\"CDB_ID\"]))\n",
    "map_endereco_to_nome = dict(zip(df_encontrados[\"Endereço\"], df_encontrados[\"Nome\"]))\n",
    "\n",
    "# Adicionar coluna CDB no dataframe original\n",
    "data[\"CDB\"] = data[\"ENDERECO_COMPLETO\"].map(map_endereco_to_id).fillna(0).astype(int)\n",
    "\n",
    "# Substituir NOME_FANTASIA pelo nome do CDB, se encontrado\n",
    "data[\"NOME_FANTASIA\"] = data.apply(\n",
    "    lambda row: map_endereco_to_nome.get(row[\"ENDERECO_COMPLETO\"], row[\"NOME_FANTASIA\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Salvar CSV final\n",
    "data.to_csv(\"dados_com_cdb.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b6c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encontrados = pd.DataFrame(encontrados).drop_duplicates(subset=[\"Endereço\"]).reset_index(drop=True)\n",
    "df_encontrados[\"CDB_ID\"] = df_encontrados.index + 1\n",
    "\n",
    "# Reorganizar colunas: CDB_ID primeiro\n",
    "cols = [\"CDB_ID\"] + [col for col in df_encontrados.columns if col != \"CDB_ID\"]\n",
    "df_encontrados = df_encontrados[cols]\n",
    "\n",
    "# Salvar CSV com CDB_ID como primeira coluna\n",
    "df_encontrados.to_csv(\"encontrados.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e52ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lê o CSV original com os dados existentes\n",
    "dados_existentes = pd.read_csv(\"dados_com_cdb.csv\")\n",
    "\n",
    "# Lê o CSV dos bares não encontrados, contendo CDB_ID, Nome e Endereço\n",
    "novos_bares = pd.read_csv(\"cdb_notfound.csv\")\n",
    "\n",
    "# Renomeia as colunas para se adequar ao padrão do CSV final\n",
    "novos_bares.rename(columns={\n",
    "    \"CDB_ID\": \"CDB\",\n",
    "    \"Nome\": \"NOME\",\n",
    "    \"Endereço\": \"ENDERECO_COMPLETO\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Adiciona as colunas faltantes com os valores definidos\n",
    "novos_bares[\"ID_ATIV_ECON_ESTABELECIMENTO\"] = \"indisponivel\"\n",
    "novos_bares[\"CNAE_PRINCIPAL\"] = \"indisponivel\"\n",
    "novos_bares[\"DATA_INICIO_ATIVIDADE\"] = \"indisponivel\"\n",
    "novos_bares[\"IND_POSSUI_ALVARA\"] = \"SIM\"\n",
    "novos_bares[\"NOME_FANTASIA\"] = \"indisponivel\"\n",
    "novos_bares[\"GEOMETRIA\"] = \"indisponivel\"\n",
    "\n",
    "# Reorganiza as colunas na mesma ordem do arquivo original\n",
    "colunas_ordenadas = [\n",
    "    \"ID_ATIV_ECON_ESTABELECIMENTO\",\n",
    "    \"CNAE_PRINCIPAL\",\n",
    "    \"DATA_INICIO_ATIVIDADE\",\n",
    "    \"IND_POSSUI_ALVARA\",\n",
    "    \"ENDERECO_COMPLETO\",\n",
    "    \"NOME\",\n",
    "    \"NOME_FANTASIA\",\n",
    "    \"GEOMETRIA\",\n",
    "    \"CDB\"\n",
    "]\n",
    "novos_bares = novos_bares[colunas_ordenadas]\n",
    "\n",
    "# Concatena os dados\n",
    "dados_atualizados = pd.concat([dados_existentes, novos_bares], ignore_index=True)\n",
    "\n",
    "# Salva no mesmo arquivo\n",
    "dados_atualizados.to_csv(\"dados_com_cdb.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "784cd76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_ATIV_ECON_ESTABELECIMENTO            object\n",
      "CNAE_PRINCIPAL                          object\n",
      "DATA_INICIO_ATIVIDADE           datetime64[ns]\n",
      "IND_POSSUI_ALVARA                       object\n",
      "ENDERECO_COMPLETO                       object\n",
      "NOME                                    object\n",
      "NOME_FANTASIA                           object\n",
      "GEOMETRIA                               object\n",
      "CDB                                      Int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# padronizar data types\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"dados_com_cdb.csv\",\n",
    "    dtype={\n",
    "        \"ID_ATIV_ECON_ESTABELECIMENTO\": str,\n",
    "        \"CNAE_PRINCIPAL\": str,\n",
    "        \"IND_POSSUI_ALVARA\": str,\n",
    "        \"ENDERECO_COMPLETO\": str,\n",
    "        \"NOME\": str,\n",
    "        \"NOME_FANTASIA\": str,\n",
    "        \"GEOMETRIA\": str,\n",
    "        \"CDB\": \"Int64\",  \n",
    "    },\n",
    "    parse_dates=[\"DATA_INICIO_ATIVIDADE\"],  # converte para datetime64\n",
    "    dayfirst=True  \n",
    ")\n",
    "df[\"DATA_INICIO_ATIVIDADE\"] = pd.to_datetime(df[\"DATA_INICIO_ATIVIDADE\"], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4597d79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
