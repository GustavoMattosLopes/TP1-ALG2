{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db00c21d",
   "metadata": {},
   "source": [
    "# Notebook para processamento dos dados de Comida di Buteco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c47ebcd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0e0e84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/luisalopescarvalhaes/.local/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: unidecode in /home/luisalopescarvalhaes/.local/lib/python3.13/site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/lib64/python3.13/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/lib/python3.13/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/luisalopescarvalhaes/.local/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/luisalopescarvalhaes/.local/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89bd64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d8ea8c",
   "metadata": {},
   "source": [
    "## Cross Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura dos dados\n",
    "data = pd.read_csv(\"../data/dados_filtrados.csv\")\n",
    "cdb = pd.read_csv(\"bares_cdb2025.csv\")\n",
    "\n",
    "# Normalização dos textos\n",
    "data[\"NOME_FANTASIA\"] = data[\"NOME_FANTASIA\"].str.upper().str.strip()\n",
    "data[\"ENDERECO_COMPLETO\"] = data[\"ENDERECO_COMPLETO\"].str.upper().str.strip()\n",
    "\n",
    "cdb[\"Nome\"] = cdb[\"Nome\"].str.upper().str.strip()\n",
    "cdb[\"Endereço\"] = cdb[\"Endereço\"].str.upper().str.strip()\n",
    "\n",
    "# Conjuntos de referência\n",
    "nomes_ref = set(data[\"NOME_FANTASIA\"])\n",
    "enderecos_ref = set(data[\"ENDERECO_COMPLETO\"])\n",
    "\n",
    "# Listas para armazenar resultados\n",
    "nao_encontrados = []\n",
    "encontrados = []\n",
    "\n",
    "# Verificação de existência\n",
    "for _, row in cdb.iterrows():\n",
    "    nome = row[\"Nome\"]\n",
    "    endereco = row[\"Endereço\"]\n",
    "\n",
    "    if endereco in enderecos_ref:\n",
    "        encontrados.append({\n",
    "            \"Nome\": nome,\n",
    "            \"Endereço\": endereco\n",
    "        })\n",
    "    else:\n",
    "        nao_encontrados.append({\n",
    "            \"Nome\": nome,\n",
    "            \"Endereço\": endereco\n",
    "        })\n",
    "\n",
    "# Impressão dos não encontrados\n",
    "for item in nao_encontrados:\n",
    "    print(f'Não encontrado: {item[\"Nome\"]} - {item[\"Endereço\"]}')\n",
    "\n",
    "# Salvando os resultados\n",
    "pd.DataFrame(nao_encontrados).to_csv(\"nao_encontrados.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "pd.DataFrame(encontrados).to_csv(\"encontrados.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2fdc07",
   "metadata": {},
   "source": [
    "## Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f52bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar(texto):\n",
    "    if pd.isna(texto):\n",
    "        return \"\"\n",
    "    return unidecode(texto.strip().upper())\n",
    "\n",
    "def extrair_rua(endereco):\n",
    "    return normalizar(endereco.split(\",\")[0])\n",
    "\n",
    "def nome_bate(nome_csv1, nome_csv2, nome_fantasia):\n",
    "    palavras = [normalizar(p) for p in nome_csv1.split()]\n",
    "    nome_csv2 = normalizar(nome_csv2)\n",
    "    nome_fantasia = normalizar(nome_fantasia)\n",
    "    return any(p in nome_csv2 or p in nome_fantasia for p in palavras)\n",
    "\n",
    "def endereco_bate(end1, end2):\n",
    "    return extrair_rua(end1) in normalizar(end2)\n",
    "\n",
    "csv1 = pd.read_csv(\"nao_encontrados.csv\") \n",
    "csv2 = pd.read_csv(\"dados_filtrados.csv\")  \n",
    "\n",
    "with open(\"matchings.txt\", \"w\", encoding=\"utf-8\") as output:\n",
    "    for _, row1 in csv1.iterrows():\n",
    "        nome1 = str(row1[\"Nome\"])\n",
    "        endereco1 = str(row1[\"Endereço\"])\n",
    "\n",
    "        output.write(f'{nome1},\"{endereco1}\"\\n')\n",
    "        output.write(\"matchings (pode haver mais de um):\\n\")\n",
    "\n",
    "        achou = False\n",
    "        for _, row2 in csv2.iterrows():\n",
    "            nome_real = str(row2.get(\"NOME\", \"\"))\n",
    "            nome_fantasia = str(row2.get(\"NOME_FANTASIA\", \"\"))\n",
    "            endereco2 = str(row2.get(\"ENDERECO_COMPLETO\", \"\"))\n",
    "\n",
    "            if nome_bate(nome1, nome_real, nome_fantasia) and endereco_bate(endereco1, endereco2):\n",
    "                output.write(f'\"{endereco2}\"{nome_fantasia, nome_real}\\n')\n",
    "                achou = True\n",
    "\n",
    "        if not achou:\n",
    "            output.write(\"Nenhum matching encontrado.\\n\")\n",
    "        output.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39bb8b",
   "metadata": {},
   "source": [
    "### Resultado do `matching.txt`\n",
    "\n",
    "**CANTINHO DA BAIANA**  \n",
    "Endereço: \"AVENIDA ITAITE, 422, SÃO GERALDO, BELO HORIZONTE, MG, BRASIL\"  \n",
    "Matchings:  \n",
    "\"AVENIDA ITAITE, 422, SAO GERALDO, BELO HORIZONTE, MG, BRASIL\"  \n",
    "*('Estabelecimento sem nome', 'CANTINHO DA BAIANA COMERCIAL LTDA')*\n",
    "\n",
    "**BAR DA LU**  \n",
    "Endereço: \"RUA GERALDA MARINHO, 41, SÃO JOÃO BATISTA, BELO HORIZONTE, MG, BRASIL\"  \n",
    "Matchings:  \n",
    "\"RUA GERALDA MARINHO, 41, SAO JOAO BATISTA, BELO HORIZONTE, MG, BRASIL\"  \n",
    "*('BAR E RESTAURANTE DA LU', '38.029.984 LUZMARINA PEREIRA DAS NEVES')*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a87c0fc",
   "metadata": {},
   "source": [
    "## Organização para o dataset final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37072e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Carregar e normalizar os dados ===\n",
    "data = pd.read_csv(\"../data/dados_filtrados.csv\")\n",
    "cdb = pd.read_csv(\"bares_cdb2025.csv\")\n",
    "\n",
    "data[\"NOME_FANTASIA\"] = data[\"NOME_FANTASIA\"].str.upper().str.strip()\n",
    "data[\"ENDERECO_COMPLETO\"] = data[\"ENDERECO_COMPLETO\"].str.upper().str.strip()\n",
    "cdb[\"Nome\"] = cdb[\"Nome\"].str.upper().str.strip()\n",
    "cdb[\"Endereço\"] = cdb[\"Endereço\"].str.upper().str.strip()\n",
    "\n",
    "# === 2. Identificar endereços coincidentes ===\n",
    "enderecos_ref = set(data[\"ENDERECO_COMPLETO\"])\n",
    "encontrados = cdb[cdb[\"Endereço\"].isin(enderecos_ref)].drop_duplicates(subset=[\"Endereço\"])\n",
    "encontrados = encontrados.reset_index(drop=True)\n",
    "encontrados[\"CDB_ID\"] = encontrados.index + 1\n",
    "\n",
    "# === 3. Criar mapeamentos e atualizar `data` com CDB_ID e nome do CDB ===\n",
    "map_endereco_to_id = dict(zip(encontrados[\"Endereço\"], encontrados[\"CDB_ID\"]))\n",
    "map_endereco_to_nome = dict(zip(encontrados[\"Endereço\"], encontrados[\"Nome\"]))\n",
    "\n",
    "data[\"CDB\"] = data[\"ENDERECO_COMPLETO\"].map(map_endereco_to_id).fillna(0).astype(int)\n",
    "data[\"NOME_FANTASIA\"] = data.apply(\n",
    "    lambda row: map_endereco_to_nome.get(row[\"ENDERECO_COMPLETO\"], row[\"NOME_FANTASIA\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# === 4. Salvar arquivos atualizados ===\n",
    "# Ordenar colunas para o CSV de encontrados\n",
    "cols = [\"CDB_ID\", \"Nome\", \"Endereço\"]\n",
    "encontrados = encontrados[cols]\n",
    "encontrados.to_csv(\"encontrados.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "data.to_csv(\"dados_com_cdb.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# === 5. Incluir bares não encontrados ===\n",
    "try:\n",
    "    novos_bares = pd.read_csv(\"cdb_notfound.csv\")\n",
    "    novos_bares.rename(columns={\n",
    "        \"CDB_ID\": \"CDB\",\n",
    "        \"Nome\": \"NOME\",\n",
    "        \"Endereço\": \"ENDERECO_COMPLETO\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Adicionar colunas padrão\n",
    "    for col, val in {\n",
    "        \"ID_ATIV_ECON_ESTABELECIMENTO\": \"indisponivel\",\n",
    "        \"CNAE_PRINCIPAL\": \"indisponivel\",\n",
    "        \"DATA_INICIO_ATIVIDADE\": \"indisponivel\",\n",
    "        \"IND_POSSUI_ALVARA\": \"SIM\",\n",
    "        \"NOME_FANTASIA\": \"indisponivel\",\n",
    "        \"GEOMETRIA\": \"indisponivel\"\n",
    "    }.items():\n",
    "        novos_bares[col] = val\n",
    "\n",
    "    # Reordenar colunas\n",
    "    colunas_ordenadas = [\n",
    "        \"ID_ATIV_ECON_ESTABELECIMENTO\", \"CNAE_PRINCIPAL\", \"DATA_INICIO_ATIVIDADE\",\n",
    "        \"IND_POSSUI_ALVARA\", \"ENDERECO_COMPLETO\", \"NOME\", \"NOME_FANTASIA\", \"GEOMETRIA\", \"CDB\"\n",
    "    ]\n",
    "    novos_bares = novos_bares[colunas_ordenadas]\n",
    "\n",
    "    # Concatenar e salvar\n",
    "    dados_atualizados = pd.concat([data, novos_bares], ignore_index=True)\n",
    "    dados_atualizados.to_csv(\"dados_com_cdb.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo 'cdb_notfound.csv' não encontrado. Pulando inclusão de novos bares.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "784cd76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padronizar data types\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"dados_com_cdb.csv\",\n",
    "    dtype={\n",
    "        \"ID_ATIV_ECON_ESTABELECIMENTO\": str,\n",
    "        \"CNAE_PRINCIPAL\": str,\n",
    "        \"IND_POSSUI_ALVARA\": str,\n",
    "        \"ENDERECO_COMPLETO\": str,\n",
    "        \"NOME\": str,\n",
    "        \"NOME_FANTASIA\": str,\n",
    "        \"GEOMETRIA\": str,\n",
    "        \"CDB\": \"Int64\",  \n",
    "    },\n",
    "    parse_dates=[\"DATA_INICIO_ATIVIDADE\"],  # converte para datetime64\n",
    "    dayfirst=True  \n",
    ")\n",
    "df[\"DATA_INICIO_ATIVIDADE\"] = pd.to_datetime(df[\"DATA_INICIO_ATIVIDADE\"], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "# print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa651630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDB_ID</th>\n",
       "      <th>NOME</th>\n",
       "      <th>ENDERECO</th>\n",
       "      <th>IMAGEM</th>\n",
       "      <th>PETISCO</th>\n",
       "      <th>DESCRICAO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>ARCOS BAR</td>\n",
       "      <td>RUA DA BAHIA, 1144, CENTRO, BELO HORIZONTE, MG...</td>\n",
       "      <td>https://s2-g1.glbimg.com/TBJlO2gBA-eoaA_0XK6kM...</td>\n",
       "      <td>Panela da Diversidade</td>\n",
       "      <td>Acem cozido com ervas finas acompanhado com ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002</td>\n",
       "      <td>AZOUGUE FOGO E BAR</td>\n",
       "      <td>RUA DO OURO, 835, SERRA, BELO HORIZONTE, MG, B...</td>\n",
       "      <td>https://s2-g1.glbimg.com/4nvx0TTUnKRrUtN5CL_bO...</td>\n",
       "      <td>Lingua da vovó Virinha</td>\n",
       "      <td>Língua de boi assada sobre creme de batata e m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003</td>\n",
       "      <td>BAIÚCA</td>\n",
       "      <td>RUA PIAUI, 1884, SAVASSI, BELO HORIZONTE, MG, ...</td>\n",
       "      <td>https://s2-g1.glbimg.com/jzIpvnVuWznTE1n1R0us6...</td>\n",
       "      <td>Canelada Suína</td>\n",
       "      <td>Panturrilha suína, mandioca cozida com queijo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004</td>\n",
       "      <td>BAR ESTABELECIMENTO</td>\n",
       "      <td>RUA MONTE ALEGRE, 160, SERRA, BELO HORIZONTE, ...</td>\n",
       "      <td>https://s2-g1.glbimg.com/XMgVOHr-0_Y9lUNhH3Fr4...</td>\n",
       "      <td>Tipracas</td>\n",
       "      <td>Pelotas de rabada com angu de agrião e \"tiprac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005</td>\n",
       "      <td>BAR MANIA MINEIRA</td>\n",
       "      <td>RUA PARACATU, 1099, SANTO AGOSTINHO, BELO HORI...</td>\n",
       "      <td>https://cdb-static-files.s3.amazonaws.com/wp-c...</td>\n",
       "      <td>EXPLOSÃO DE SABOR</td>\n",
       "      <td>Bolinho de mandioca recheado com queijo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CDB_ID                 NOME  \\\n",
       "0    001            ARCOS BAR   \n",
       "1    002   AZOUGUE FOGO E BAR   \n",
       "2    003               BAIÚCA   \n",
       "3    004  BAR ESTABELECIMENTO   \n",
       "4    005    BAR MANIA MINEIRA   \n",
       "\n",
       "                                            ENDERECO  \\\n",
       "0  RUA DA BAHIA, 1144, CENTRO, BELO HORIZONTE, MG...   \n",
       "1  RUA DO OURO, 835, SERRA, BELO HORIZONTE, MG, B...   \n",
       "2  RUA PIAUI, 1884, SAVASSI, BELO HORIZONTE, MG, ...   \n",
       "3  RUA MONTE ALEGRE, 160, SERRA, BELO HORIZONTE, ...   \n",
       "4  RUA PARACATU, 1099, SANTO AGOSTINHO, BELO HORI...   \n",
       "\n",
       "                                              IMAGEM                 PETISCO  \\\n",
       "0  https://s2-g1.glbimg.com/TBJlO2gBA-eoaA_0XK6kM...   Panela da Diversidade   \n",
       "1  https://s2-g1.glbimg.com/4nvx0TTUnKRrUtN5CL_bO...  Lingua da vovó Virinha   \n",
       "2  https://s2-g1.glbimg.com/jzIpvnVuWznTE1n1R0us6...          Canelada Suína   \n",
       "3  https://s2-g1.glbimg.com/XMgVOHr-0_Y9lUNhH3Fr4...                Tipracas   \n",
       "4  https://cdb-static-files.s3.amazonaws.com/wp-c...       EXPLOSÃO DE SABOR   \n",
       "\n",
       "                                           DESCRICAO  \n",
       "0  Acem cozido com ervas finas acompanhado com ba...  \n",
       "1  Língua de boi assada sobre creme de batata e m...  \n",
       "2  Panturrilha suína, mandioca cozida com queijo ...  \n",
       "3  Pelotas de rabada com angu de agrião e \"tiprac...  \n",
       "4            Bolinho de mandioca recheado com queijo  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"cdb_data.csv\")\n",
    "df2 =  pd.read_csv(\"bares_cdb2025.csv\")\n",
    "\n",
    "df2[\"Nome\"] = df2[\"Nome\"].str.strip('\"')\n",
    "\n",
    "df1[\"Nome_upper\"] = df1[\"Nome\"].str.upper()\n",
    "df2[\"Nome_upper\"] = df2[\"Nome\"].str.upper()\n",
    "\n",
    "df1[\"CDB_ID\"] = df1[\"CDB_ID\"].apply(lambda x: f\"{int(x):03d}\")\n",
    "\n",
    "df_merged = pd.merge(df1, df2, on=\"Nome_upper\", how=\"left\")\n",
    "\n",
    "df_merged = df_merged.drop(columns=[\"Nome_upper\"])\n",
    "df_merged.rename(columns={\"Nome\": \"NOME\"}, inplace=True)\n",
    "\n",
    "df_merged[\"NOME\"] = df_merged[\"Nome_x\"]\n",
    "df_merged[\"ENDERECO\"] = df_merged[\"Endereço_x\"]\n",
    "\n",
    "\n",
    "df_merged.rename(columns={\n",
    "    \"Imagem\": \"IMAGEM\",\n",
    "    \"Petisco\": \"PETISCO\",\n",
    "    \"Descrição do petisco\": \"DESCRICAO\"\n",
    "}, inplace=True)\n",
    "\n",
    "df_final = df_merged[[\"CDB_ID\", \"NOME\", \"ENDERECO\", \"IMAGEM\", \"PETISCO\", \"DESCRICAO\"]]\n",
    "\n",
    "df_final.to_csv(\"complete_cdb_data.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8203381d",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Após o processo de matching automático e os ajustes manuais realizados, obtivemos um datasets principal:\n",
    "\n",
    " **`complete_cdb_data.csv`**\n",
    "\n",
    "Este arquivo contém as informações completas e padronizadas dos bares participantes do Comida di Buteco. As colunas presentes são:\n",
    "\n",
    "- : identificador único do bar.\n",
    "- `NOME`: nome oficial do estabelecimento.\n",
    "- `ENDERECO`: endereço completo do bar.\n",
    "- `IMAGEM`: URL da imagem representativa do bar ou do petisco.\n",
    "- `PETISCO`: nome do petisco inscrito no concurso.\n",
    "- `DESCRICAO`: descrição detalhada do petisco.\n",
    "\n",
    "Vamos usar o `CDB_ID` como chave estrangeira para linkar os dados do Comida di Buteco com os dados gerais dos bares e restaurantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679c36e2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
